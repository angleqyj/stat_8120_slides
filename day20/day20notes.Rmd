---
title: "Day 20"
author: "Taylor R. Brown"
date: "1/4/2020"
output: slidy_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Roadmap

9.1

- back to non-time series situation

- importance sampling -> self-normalized importance sampling

- mostly proof-free (classical asymptotics)

9.2

- **sampling importance resampling/IS with resampling/factored sampling** 

9.3

- sequential importance sampling with resampling (single-step analysis)

9.4

- sequential importance sampling with resampling (multi-step analysis)


## Overview

```{r, echo=F, out.width="500px"}
knitr::include_graphics("SIR.png")
```



## Today

Last class, we showed that SIR produces consistent estimators. This was Theorem 9.2.9.

Now we want to show that SIR estiamtors are asymptotically normal. 

We do this in two steps:

1. re-weighting preserves asymptotic normality
2. resampling preserves asymptotic normality


## Assumption 9.2.10

This is reasonable to assume because it is often guaranteed by the "standard" CLT.

Assumption 9.2.10: The weighted sample $\{(\xi^{N,i}, \omega^{N,i})\}_{1 \le i \le M_N}$ is asymptotically normal for $(\nu, \mathsf{A}, \sigma, \{a_N\})$, and $\frac{d\mu}{d\nu} \in \mathsf{A}$.

Keep in mind that

- $\mathsf{A}$ is proper
- $\sigma$ is nonnegative
- $a_N \uparrow \infty$


## Theorem 9.2.11

Assume these three:

Assumption 9.1.1: $\mu \ll \nu$, and $d\mu/d\nu > 0$ almost surely.

Assumption 9.2.6: $\{(\xi^{N,i}, \omega^{N,i} )\}_{1 \le i \le M_N}$ is consistent for $(\nu, \mathsf{C})$ (a proper set), and $d\mu/d\nu \in \mathsf{C}$. 

Assumption 9.2.10: The weighted sample $\{(\xi^{N,i}, \omega^{N,i})\}_{1 \le i \le M_N}$ is asymptotically normal for $(\nu, \mathsf{A}, \sigma, \{a_N\})$, and $\frac{d\mu}{d\nu} \in \mathsf{A}$.

Then ...


## Theorem 9.2.11

Then

$$
\bar{\mathsf{A}} = \left\{ f \in L^2(\mathsf{X}, \mu) : |f| \frac{d\mu}{d\nu} \in \mathsf{A} \right\}
$$
is a proper set, and the weighted sample $\{(\xi^{N,i}, \omega^{N,i} \frac{d\mu}{d\nu}(\xi^{N,i}) )\}_{1 \le i \le M_N}$ is asymptotically normal for $(\mu, \bar{\mathsf{A}}, \bar{\sigma}, \{a_N\})$.

The new asymptotic variance functional is 
$$
\bar{\sigma}^2(f) = \sigma^2\left( \frac{d\mu}{d\nu}[f - \mu(f)]  \right).
$$


## Theorem 9.2.11: proof (1 of 3)

First, show 
$$
\bar{\mathsf{A}} = \left\{ f \in L^2(\mathsf{X}, \mu) : |f| \frac{d\mu}{d\nu} \in \mathsf{A} \right\}
$$
is proper. 

In class exercise! Hint: we followed the same steps in an earlier proof.


## Theorem 9.2.11: proof (2 of 3)

General idea: rewrite

$$
a_N\left\{ \sum_{i=1}^{M_N} \frac{ \omega^{N,i}\frac{d\mu}{d\nu}(\xi^{N,i})  }{ \sum_j \omega^{N,i}\frac{d\mu}{d\nu}(\xi^{N,i}) } [f(\xi^{N,i}) - \mu(f)]  \right\}
$$
as
$$  
\frac{ a_N \sum_{i=1}^{M_N} \frac{\omega^{N,i}}{\sum_j \omega^{N,j}}\frac{d\mu}{d\nu}(\xi^{N,i})[f(\xi^{N,i}) - \mu(f)]  }{  \sum_j \frac{ \omega^{N,i} }{ \sum_k \omega^{N,k} }\frac{d\mu}{d\nu}(\xi^{N,i}) } 
$$
and see the numerator converges in distribution, the denominator converges in probability; then use Slutsky's.



## Theorem 9.2.11: proof (3 of 3)

If $f \in \bar{\mathsf{A}}$, then $f\frac{d\mu}{d\nu} \in \mathsf{A}$ (definition of $\tilde{\mathsf{A}}$) and  $f\frac{d\mu}{d\nu} \in \mathsf{A}$ (assumption 9.2.10). Because $\mathsf{A}$ is proper, $h = \frac{d\mu}{d\nu} (f - \mu(f)) \in \mathsf{A}$ (linear combinations!) and so the numerator:
$$
a_N \sum_{i=1}^{M_N} \frac{\omega^{N,i}}{\sum_j \omega^{N,j}}\frac{d\mu}{d\nu}(\xi^{N,i})[f(\xi^{N,i}) - \mu(f)]   \overset{\text{D}}{\to}  \text{Normal}\left(0, \bar{\sigma}^2(f)\right)
$$
(be sure to work out the mean/variance!).

The denominator 
$$
 \sum_j \frac{ \omega^{N,i} }{ \sum_k \omega^{N,k} }\frac{d\mu}{d\nu}(\xi^{N,i})  \overset{\text{p}}{\to} 1 = \nu\left(\frac{d\mu}{d\nu} \right)
$$
as long as $\frac{d\mu}{d\nu} \in \mathsf{C}$, and this is true by assumption 9.2.6.




## Proposition 9.2.12

This is a stepping stone to the final theorem: Theorem 9.2.14. Its proof uses Proposition 9.5.13 (see day 14 notes).

Assume 

Assumption 9.1.1: $\mu \ll \nu$, and $d\mu/d\nu > 0$ almost surely.

Assumption 9.2.6: $\{(\xi^{N,i}, \omega^{N,i} )\}_{1 \le i \le M_N}$ is consistent for $(\nu, \mathsf{C})$ (a proper set), and $d\mu/d\nu \in \mathsf{C}$. 

Also, assume $\mu \in \mathbb{R}$ and $f$ is such that $f^2 \frac{d\mu}{d\nu} \in \mathsf{C}$. 

Then ...

## Proposition 9.2.12

Then the conditional characteristic function
$$
E\left[ \exp\left( i u \tilde{M}_N^{-1/2} \sum_{i=1}^{\tilde{M_N}} \{ f(\tilde{\xi}^{N,i}) - E[f(\tilde{\xi}^{N,i}) \mid \mathcal{F}^N ]   \} \right)  \Bigg\rvert \mathcal{F}^N \right]
$$

converges in probability to a normal characteristic function
$$
\exp\left[ - u^2  \text{Var}_{\mu} (f) /2  \right].
$$


## Proposition 9.2.12: proof (1 of 3)

Verifying condition 1 of 3 of Proposition 9.5.13:


1. The triangular array is conditionally independent given $\{\mathcal{F}^{N}\}$, and for any $N$, $i=1,\ldots,M_N$, we have $E[f(\xi^{N,i})^2 \mid \mathcal{F}^N] < \infty$,

The conditional independent is assumed by the description of Algorithm 9.2.5. 

Also, each $E[f(\xi^{N,i})^2 \mid \mathcal{F}^N]$ should be assumed to be finite more explicitly because all the assumptions are about is what they converge to! The book glosses over this a little.



## Proposition 9.2.12: proof (2 of 3)

Verifying condition 2 of 3 of Proposition 9.5.13:

2. there exists a constant $\sigma^2 > 0$ such that
$$
\tilde{M}_N^{-1}\sum_{i=1}^{\tilde{M}_N} \left\{ E[f^2(\tilde{\xi}^{N,i}) \mid \mathcal{F}^N] - \left( E[f(\tilde{\xi}^{N,i}) \mid \mathcal{F}^N] \right)^2 \right\} \overset{\text{p}}{\to} \sigma^2,
$$



## Proposition 9.2.12: proof (2 of 3) (continued)

By identicalness
$$
\tilde{M}_N^{-1}\sum_{i=1}^{\tilde{M}_N} E[f^2(\tilde{\xi}^{N,i}) \mid \mathcal{F}^N] = E[f^2(\tilde{\xi}^{N,i}) \mid \mathcal{F}^N]
$$
and then
$$
E[f(\tilde{\xi}^{N,i})^2 \mid \mathcal{F}^N] = \sum_{i=1}^{M_N} \frac{ \omega^{N,i} \frac{d\mu}{d\nu}(\xi^{N,i}) }{ \sum_j \omega^{N,j} \frac{d\mu}{d\nu}(\xi^{N,j}) } f(\xi^{N,i})^2 
=  \frac{ \sum_{i=1}^{M_N}\frac{\omega^{N,i}}{\sum_k \omega^{N,k}} \frac{d\mu}{d\nu}(\xi^{N,i})f(\xi^{N,i})^2   }{ \sum_j \frac{\omega^{N,j}}{\sum_k \omega^{N,k} } \frac{d\mu}{d\nu}(\xi^{N,j}) } 
$$

- $f^2 \frac{d\mu}{d\nu} \in \mathsf{C}$ by the last assumption
- $\frac{d\mu}{d\nu} \in \mathsf{C}$ by assumption 9.2.6


## Proposition 9.2.12: proof (2 of 3) (continued)


The second term can be turned into one summand by identicalness as well. Then
$$
\left( E[f(\tilde{\xi}^{N,i}) \mid \mathcal{F}^N] \right)^2 = \left( \sum_{i=1}^{M_N} \frac{ \omega^{N,i} \frac{d\mu}{d\nu}(\xi^{N,i}) }{ \sum_j \omega^{N,j} \frac{d\mu}{d\nu}(\xi^{N,j}) } f(\xi^{N,i})   \right)^2
$$
The term inside the parentheses will converge by Theorem 9.2.7 if we can show that $f \in \tilde{\mathsf{C}}$ (i.e that $|f| \frac{d\mu}{d\nu} \in \mathsf{C}$).

- $f^2 \frac{d\mu}{d\nu} \in \mathsf{C}$ by the last assumption
- $\frac{d\mu}{d\nu} \in \mathsf{C}$ by assumption 9.2.6

\begin{align*}
|f| \frac{d\mu}{d\nu} &= |f| \frac{d\mu}{d\nu}\mathbb{1}(|f| \le 1) + |f| \frac{d\mu}{d\nu} \mathbb{1}(|f| > 1) \\
&\le \frac{d\mu}{d\nu}\mathbb{1}(|f| \le 1) + f^2 \frac{d\mu}{d\nu} \mathbb{1}(|f| > 1) \\
&\le \frac{d\mu}{d\nu} + f^2 \frac{d\mu}{d\nu} \in \mathsf{C}
\end{align*}

## Proposition 9.2.12: proof (3 of 3)

The third assumption of Proposition 9.5.13 is:

3. There exists a probability measure $\mu$ on $(\mathsf{X}, \mathcal{X})$ such that, if $f \in L^2(\mathsf{X}, \mu)$, and for any $C > 0$
$$
\tilde{M}_N^{-1} \sum_{i=1}^{\tilde{M}_N} E[f^2( \tilde{\xi}^{N,i}) \mathbb{1}\left( |f(\tilde{\xi}^{N,i})| \ge C \right) \mid \mathcal{F}^N] \overset{\text{p}}{\to} \mu(f^2\mathbb{1}\left( |f| \ge C \right))
$$

Rewriting the left hand side and using identicalness...

## Proposition 9.2.12: proof (3 of 3) (continued)

\begin{align*}
&E[f(\tilde{\xi}^{N,i})^2 \mathbb{1}\left( |f(\tilde{\xi}^{N,i})| \ge C \right) \mid \mathcal{F}^N] \\
&= \sum_{i=1}^{M_N} \frac{ \omega^{N,i} \frac{d\mu}{d\nu}(\xi^{N,i}) }{ \sum_j \omega^{N,j} \frac{d\mu}{d\nu}(\xi^{N,j}) } f(\xi^{N,i})^2 \mathbb{1}\left( |f(\tilde{\xi}^{N,i})| \ge C \right) \\
&=  \frac{ \sum_{i=1}^{M_N}\frac{\omega^{N,i}}{\sum_k \omega^{N,k}} \frac{d\mu}{d\nu}(\xi^{N,i})f(\xi^{N,i})^2 \mathbb{1}\left( |f(\tilde{\xi}^{N,i})| \ge C \right)  }{ \sum_j \frac{\omega^{N,j}}{\sum_k \omega^{N,k} } \frac{d\mu}{d\nu}(\xi^{N,j}) } 
\end{align*}

Numerator converges to $\mu(f^2 \mathbb{1}\left( |f| \ge C \right))$ because

- $f^2 \frac{d\mu}{d\nu} \in \mathsf{C}$ by the last assumption
- $f^2 \frac{d\mu}{d\nu}\mathbb{1}\left( |f(\tilde{\xi}^{N,i})| \ge C \right)\le f^2 \frac{d\mu}{d\nu} \in \mathsf{C}$ (so the left hand side is in $\mathsf{C}$ by proper-ness)


## Proposition 9.2.12: proof (3 of 3) (continued)

\begin{align*}
&E[f(\tilde{\xi}^{N,i})^2 \mathbb{1}\left( |f(\tilde{\xi}^{N,i})| \ge C \right) \mid \mathcal{F}^N] \\
&= \sum_{i=1}^{M_N} \frac{ \omega^{N,i} \frac{d\mu}{d\nu}(\xi^{N,i}) }{ \sum_j \omega^{N,j} \frac{d\mu}{d\nu}(\xi^{N,j}) } f(\xi^{N,i})^2 \mathbb{1}\left( |f(\tilde{\xi}^{N,i})| \ge C \right) \\
&=  \frac{ \sum_{i=1}^{M_N}\frac{\omega^{N,i}}{\sum_k \omega^{N,k}} \frac{d\mu}{d\nu}(\xi^{N,i})f(\xi^{N,i})^2 \mathbb{1}\left( |f(\tilde{\xi}^{N,i})| \ge C \right)  }{ \sum_j \frac{\omega^{N,j}}{\sum_k \omega^{N,k} } \frac{d\mu}{d\nu}(\xi^{N,j}) } 
\end{align*}

Denominator converges to $1$ because

- $\frac{d\mu}{d\nu} \in \mathsf{C}$ by assumption 9.2.6



## Theorem 9.2.14

This theorem shows that resampling preserves asymptotic normality, and describes how much the asymptotic variance increases once you resample.

Assume:

Assumption 9.1.1: $\mu \ll \nu$, and $d\mu/d\nu > 0$ almost surely.

Assumption 9.2.6: $\{(\xi^{N,i}, \omega^{N,i} )\}_{1 \le i \le M_N}$ is consistent for $(\nu, \mathsf{C})$ (a proper set), and $d\mu/d\nu \in \mathsf{C}$. 

Assumption 9.2.10: The weighted sample $\{(\xi^{N,i}, \omega^{N,i})\}_{1 \le i \le M_N}$ is asymptotically normal for $(\nu, \mathsf{A}, \sigma, \{a_N\})$, and $\frac{d\mu}{d\nu} \in \mathsf{A}$.

Last, $a^2_N / \tilde{M}_N \to \alpha$ and 
$$
\tilde{\mathsf{A}} \overset{\text{def}}{=} \left\{ f \in L^2(\mathsf{X}, \mu) : |f| \frac{d\mu}{d\nu} \in \mathsf{A}, f^2 \frac{d\mu}{d\nu} \in \mathsf{C} \right\}.
$$

Then...


## Theorem 9.2.14

...then $\tilde{\mathsf{A}}$ is proper and 

1. $\{ (\tilde{\xi}^{N,i}, 1) \}_{1 \le i \le \tilde{M}_N}$ is asymptotically normal for $(\mu, \tilde{\mathsf{A}}, \tilde{\sigma}, \{ a_N \})$ with 
$$
\tilde{\sigma}^2(f) = \alpha \text{Var}_{\mu}(f) + \sigma^2\left( \frac{d\mu}{d\nu}\left[f - \mu(f) \right] \right)
$$ 
if $\alpha < 1$ and $f \in \tilde{\mathsf{A}}$, and

2.  $\{ (\tilde{\xi}^{N,i}, 1) \}_{1 \le i \le \tilde{M}_N}$ is asymptotically normal for $(\mu, \tilde{\mathsf{A}}, \tilde{\sigma}, \{ \sqrt{ \tilde{M}_N} \})$ with 
$$
\tilde{\sigma}^2(f) = \text{Var}_{\mu}(f) + \frac{1}{\alpha} \sigma^2\left( \frac{d\mu}{d\nu}\left[f - \mu(f) \right] \right)
$$ 
if $\alpha \ge 1$ and $f \in \tilde{\mathsf{A}}$.




## Theorem 9.2.14: proof

First, let's show $\tilde{\mathsf{A}}$ is proper. This you can do on your own.

The rest of the details are given in \verb|proof_9.2.14.pdf|.

Theorem 9.2.15 is just a summary with different notation. For homework, take a look at the rest of the chapter's examples, (ignore the inequalities on tail probabilities).